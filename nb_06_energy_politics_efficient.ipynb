{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ebd843",
   "metadata": {},
   "source": [
    "# External Shock on Energy Politics with new source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "595b8846-15bd-48cd-b812-e04bc8973a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from math import log\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import stylecloud\n",
    "\n",
    "from src.keywords import ANTI_NUCLEAR, CONSERVATIVE_ENERGY, NEUTRAL_ENERGY, PRO_NUCLEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c15256-8c5a-4c01-a4a9-58aa5b47955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_AVAIL = os.path.exists(\"df_prep.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3feccf",
   "metadata": {},
   "source": [
    "## Energy Politics Keywords\n",
    "The keyword lists from `src/keywords.py` are handcrafted with the help of the topic models in notebook 03. Assignment to a category is guided by these questions:\n",
    "\n",
    "- Is <keyword> helping to leave nuclear energy (in a sustainable manner)? If yes, the topic is **anti nulcear**.\n",
    "- Is <keyword> helping to keep nuclear energy? If yes, the topic is **pro nuclear**.\n",
    "- Is <keyword> associated with conservative energy and does not fit into the above categories? If yes, the topic is **conservative energy**.\n",
    "- Is <keyword> directly associated with energy politics but does not fit into the above categories? If yes, the topic is **neutral energy**.\n",
    "\n",
    "### Stylecloud with keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1615140b-f30b-4667-a15a-7ef1d56daf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(ANTI_NUCLEAR + CONSERVATIVE_ENERGY + NEUTRAL_ENERGY + PRO_NUCLEAR)\n",
    "stylecloud.gen_stylecloud(\n",
    "    text=text,\n",
    "    icon_name=\"fas fa-atom\",\n",
    "    palette=\"colorbrewer.qualitative.Dark2_8\",\n",
    "    background_color=\"black\",\n",
    "    gradient=\"horizontal\",\n",
    "    output_name=\"docs/atom.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531177e",
   "metadata": {},
   "source": [
    "![atom wordcloud](docs/atom.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67376176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizes all topic models in a list of lists\n",
    "TOPICS = [ANTI_NUCLEAR, PRO_NUCLEAR, NEUTRAL_ENERGY, CONSERVATIVE_ENERGY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28746efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topics_extension(topic):\n",
    "    \"\"\"Extends topic models by lemmatized values of existing content\"\"\"\n",
    "    for i in range(0, len(topic)):\n",
    "        doc = gerNLP(topic[i])  # creates the spaCy document per word\n",
    "        if (\n",
    "            doc != doc[0].lemma_\n",
    "        ):  # states condition: lemma has to differ from existing item value\n",
    "            topic.extend(\n",
    "                [doc[0].lemma_]\n",
    "            )  # adds the lemmatized value to the respective topic model list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aa59c0-1aa7-4330-81aa-09c208db87f6",
   "metadata": {},
   "source": [
    "### Dataframe Preparation\n",
    "- filter out all speeches not related to energy politics\n",
    "- create a dummy variable whether a speech was given before or after the external shock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0616aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "gerNLP = spacy.load(\"de_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07472325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies topic extension\n",
    "for i in range(0, len(TOPICS)):\n",
    "    topics_extension(TOPICS[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74f03ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_KEYWORDS = ANTI_NUCLEAR + PRO_NUCLEAR + NEUTRAL_ENERGY + CONSERVATIVE_ENERGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c227cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not DF_AVAIL:\n",
    "    df = pd.read_csv(\"data/open_discourse/speeches.csv\", parse_dates=[\"date\"])\n",
    "    df.rename(columns={\"speechContent\": \"text\"}, inplace=True)\n",
    "    print(\"Prior shape\", df.shape)\n",
    "    # drops speech entries without content\n",
    "    print(\"Speech entries without content\", sum(df[\"text\"].isnull()))\n",
    "    df.dropna(subset=[\"text\"], inplace=True)\n",
    "    # If executable, this filters all speeches and keeps only those which include at least one word from the hardcoded keywords later in the notebook\n",
    "    df = df[df[\"text\"].str.contains(\"|\".join(ALL_KEYWORDS))].copy()\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(\"Shape after filter\", df.shape)\n",
    "    df[\"after_shock\"] = np.where(df[\"date\"] < pd.Timestamp(year=2011, month=3, day=11), False, True)\n",
    "    df.to_pickle(\"df_prep.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2492364-4f42-4d0a-b343-6e24761667bb",
   "metadata": {},
   "source": [
    "The column *after_shock* is a dummy variable to indicate whether a speech fragment is part of a plenary meeting before the catastrophy in Fukushima or thereafter. The inflection point is between the plenary meetings 97 and 98 during the 17th legislative period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f472e3",
   "metadata": {},
   "source": [
    "### Opinion Analysis Algorithm\n",
    "\n",
    "The class `OpinionAnalyzer()` implements\n",
    "\n",
    "- columns to store keywords and their sentiments as well as numeric scores\n",
    "- counters to track occurances of cases\n",
    "- method `calc_scores` takes a list of words and a list of associated negations and returns a total sentiment score of the list and a list documenting the score calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f9b2b3",
   "metadata": {},
   "source": [
    "## Algorithm Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07a97172-6ff9-4e87-b36a-15adb325a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"df_prep.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "814f0989-9c87-4d9b-8c50-3eb485fb75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.opinion_logic import OpinionAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "049a6b4e-a646-4e67-9720-857a9966c03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 40422 documents parsed in 0:00:35\n",
      "500 of 40422 documents parsed in 0:43:31\n",
      "1000 of 40422 documents parsed in 3:36:11\n",
      "1500 of 40422 documents parsed in 2:07:40\n",
      "2000 of 40422 documents parsed in 1:43:41\n",
      "2500 of 40422 documents parsed in 1:05:02\n",
      "3000 of 40422 documents parsed in 1:03:56\n",
      "3500 of 40422 documents parsed in 1:07:44\n",
      "4000 of 40422 documents parsed in 0:29:45\n",
      "4500 of 40422 documents parsed in 0:25:12\n",
      "5000 of 40422 documents parsed in 0:40:15\n",
      "5500 of 40422 documents parsed in 0:57:51\n",
      "6000 of 40422 documents parsed in 1:20:48\n",
      "6500 of 40422 documents parsed in 0:50:34\n",
      "7000 of 40422 documents parsed in 0:47:15\n",
      "7500 of 40422 documents parsed in 1:39:22\n",
      "8000 of 40422 documents parsed in 1:03:12\n",
      "8500 of 40422 documents parsed in 0:47:44\n",
      "9000 of 40422 documents parsed in 0:46:25\n",
      "9500 of 40422 documents parsed in 0:42:28\n",
      "10000 of 40422 documents parsed in 0:31:49\n",
      "10500 of 40422 documents parsed in 0:22:20\n",
      "11000 of 40422 documents parsed in 0:24:59\n",
      "11500 of 40422 documents parsed in 0:57:12\n",
      "12000 of 40422 documents parsed in 0:32:31\n",
      "12500 of 40422 documents parsed in 0:21:06\n",
      "13000 of 40422 documents parsed in 0:23:05\n",
      "13500 of 40422 documents parsed in 0:23:18\n",
      "14000 of 40422 documents parsed in 0:28:03\n",
      "14500 of 40422 documents parsed in 0:25:28\n",
      "15000 of 40422 documents parsed in 0:36:17\n",
      "15500 of 40422 documents parsed in 0:31:22\n",
      "16000 of 40422 documents parsed in 0:23:53\n",
      "16500 of 40422 documents parsed in 0:23:02\n",
      "17000 of 40422 documents parsed in 0:41:33\n",
      "17500 of 40422 documents parsed in 0:39:38\n",
      "18000 of 40422 documents parsed in 0:46:02\n",
      "18500 of 40422 documents parsed in 0:23:42\n",
      "19000 of 40422 documents parsed in 0:43:36\n",
      "19500 of 40422 documents parsed in 0:50:15\n",
      "20000 of 40422 documents parsed in 0:58:22\n",
      "20500 of 40422 documents parsed in 1:26:41\n",
      "21000 of 40422 documents parsed in 1:22:33\n",
      "21500 of 40422 documents parsed in 1:20:04\n",
      "22000 of 40422 documents parsed in 1:04:31\n",
      "22500 of 40422 documents parsed in 1:05:23\n",
      "23000 of 40422 documents parsed in 1:28:08\n",
      "23500 of 40422 documents parsed in 1:26:24\n",
      "24000 of 40422 documents parsed in 1:17:29\n",
      "24500 of 40422 documents parsed in 1:15:59\n",
      "25000 of 40422 documents parsed in 1:40:28\n",
      "25500 of 40422 documents parsed in 1:07:28\n",
      "26000 of 40422 documents parsed in 0:59:25\n",
      "26500 of 40422 documents parsed in 1:34:46\n",
      "27000 of 40422 documents parsed in 1:14:16\n",
      "27500 of 40422 documents parsed in 1:10:43\n",
      "28000 of 40422 documents parsed in 1:01:46\n",
      "28500 of 40422 documents parsed in 1:03:54\n",
      "29000 of 40422 documents parsed in 1:35:24\n",
      "29500 of 40422 documents parsed in 1:20:14\n",
      "30000 of 40422 documents parsed in 1:36:15\n",
      "30500 of 40422 documents parsed in 1:13:08\n",
      "31000 of 40422 documents parsed in 1:43:45\n",
      "31500 of 40422 documents parsed in 1:00:20\n",
      "32000 of 40422 documents parsed in 1:18:11\n",
      "32500 of 40422 documents parsed in 1:27:16\n",
      "33000 of 40422 documents parsed in 1:14:48\n",
      "33500 of 40422 documents parsed in 1:04:31\n",
      "34000 of 40422 documents parsed in 2:02:26\n",
      "34500 of 40422 documents parsed in 1:36:37\n",
      "35000 of 40422 documents parsed in 1:36:01\n",
      "35500 of 40422 documents parsed in 0:57:10\n",
      "36000 of 40422 documents parsed in 1:04:11\n",
      "36500 of 40422 documents parsed in 1:06:49\n",
      "37000 of 40422 documents parsed in 1:08:30\n",
      "37500 of 40422 documents parsed in 1:28:46\n",
      "38000 of 40422 documents parsed in 1:18:27\n",
      "38500 of 40422 documents parsed in 0:39:08\n",
      "39000 of 40422 documents parsed in 0:49:55\n",
      "39500 of 40422 documents parsed in 0:43:37\n",
      "40000 of 40422 documents parsed in 0:45:01\n",
      "CPU times: user 2d 10h 4min 29s, sys: 13h 8min 3s, total: 2d 23h 12min 33s\n",
      "Wall time: 3d 12h 57min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The algorithm processing duration was 5097.0 minutes.\\n115722 occurances of keywords were identified\\n86522315 words within keywords' subtrees were checked.\\n82050535 words within keywords' ancestors were checked.\\n0 keywords were used in statements attributed to somebody else by the speaker.\\n0 keywords descriptions were negated.\\n163470616 descriptions of keywords were neutral.\\n1456835 descriptions of keywords were negative.\\n3645399 descriptions of keywords were positive.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_pickle(\"df_prep.pkl\")\n",
    "opinion = OpinionAnalyzer(df)\n",
    "df = opinion.main(batch_size=2, n_process=6)\n",
    "opinion.protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e585b6-b8fa-4d47-91aa-438835828ade",
   "metadata": {},
   "source": [
    "Sample processing performance of 500 documents shown in table below.\n",
    "\n",
    "| batch_size | n_process | wall time | cpu time |\n",
    "|-|-|-|-|\n",
    "| 200 | 2 | 2h 14min | 1h 8min |\n",
    "| 20 | 6 | 1h 33min | 1h 5min |\n",
    "| 2 | 8 | 1h 6min | 1h 8min |\n",
    "| 2 | 12 | 1h 8min | 1h 4min |\n",
    "| 1 | 12 | 1h 53min | 1h 15min |\n",
    "| 5 | 12 | 3h 24min | 3h 21min |\n",
    "| 1 | 24 | 4h 29 min | 4h 18min |\n",
    "| 4 | 8 | 1h 26min | 1h 7min |\n",
    "| 2 | 6 | 1h 7min | 1h 6min |\n",
    "| 2 | 4 | 1h 55min | 1h 20min |\n",
    "| 2 | 2 | 1h 29min | 1h 28min |\n",
    "| 2 | 1 | 1h 29min | 1h 29min |\n",
    "| 18 | 2 | 1h 5min | 1h 5min |\n",
    "| 2 | 18 | 1h 46min | 1h 7min |\n",
    "| 15 | 4 | 1h 13min | 1h 11min |\n",
    "| 4 | 8 | 1h 26min | 1h 7min |\n",
    "| 2 | 18 | 1h 46min | 1h 7min |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "495ee2f2-06bc-4a08-9ff7-2db2df1371fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "    \n",
    "with open(\"opinion.pkl\", \"wb\") as f:\n",
    "    pickle.dump(opinion, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef15821",
   "metadata": {},
   "source": [
    "### Score Splitting at Inflection Point\n",
    "As it is essential to compare opinions before and after the external shock, both values extracted from the calculated scores in the various categories in conjunction with the dummy variable *after_shock*, which is 0 for pre-shock and 1 for after-shock speech fragments. <br>\n",
    "To do so, pre-shock and after-shock columns for each category are created (i.e. *NE_sp*, *PN_sa*). These are children to the main category score columns (i.e. *NE_s*, *PN_s*). Initially, the children columns take on the same value as the parents. Then, the values are adjusted to 0 if the *after_shock* variable value (0 or 1) does not match with the children score column suffices (pre or after). Accordingly, for all rows with a *after_shock* value of 1, the pre score will be reset to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "381961d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets all children score columns to equal the parents' values\n",
    "df[\"AN_sp\"] = df[\"AN_s\"]\n",
    "df[\"AN_sa\"] = df[\"AN_s\"]\n",
    "\n",
    "df[\"PN_sp\"] = df[\"PN_s\"]\n",
    "df[\"PN_sa\"] = df[\"PN_s\"]\n",
    "\n",
    "df[\"NE_sp\"] = df[\"NE_s\"]\n",
    "df[\"NE_sa\"] = df[\"NE_s\"]\n",
    "\n",
    "df[\"CE_sp\"] = df[\"CE_s\"]\n",
    "df[\"CE_sa\"] = df[\"CE_s\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a1ff0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusts children score columns for their after_shock values\n",
    "df.loc[df.after_shock == 1, [\"AN_sp\", \"PN_sp\", \"NE_sp\", \"CE_sp\"]] = 0\n",
    "df.loc[df.after_shock == 0, [\"AN_sa\", \"PN_sa\", \"NE_sa\", \"CE_sa\"]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53378def",
   "metadata": {},
   "source": [
    "### Score Calculation\n",
    "The main score is calculated using three of the four keyword lists. The score is designed to be positive to reflect progressiveness. Therefore, anti-nuclear energy opinions are added, pro-nuclear energy opinions are substracted, and conservative energy politics opinions are substracted as well, as those do not reflect the turnaround performed by politics. Solely opinions about energy politics which do not fall into any of the other three categories are not included in the score but are kept for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4aae7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"] = df[\"AN_s\"] - df[\"PN_s\"] - df[\"CE_s\"]\n",
    "df[\"score_p\"] = df[\"AN_sp\"] - df[\"PN_sp\"] - df[\"CE_sp\"]\n",
    "df[\"score_a\"] = df[\"AN_sa\"] - df[\"PN_sa\"] - df[\"CE_sa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3e9225",
   "metadata": {},
   "source": [
    "### Delay Weight\n",
    "#### Weight Calculation\n",
    "The delay weight assigns a value between $1$ and $\\log_{log\\_base}(\\infty)$ to each row. Later, the score will be divided by the weight to calculate the tenacity. The later a speech was given after the external shock, the less impact its score has. The delay weight will be useful in the calculation of the measure of tenacity.\n",
    "<br>\n",
    "The column *delay* is supposed to indicate how many sessions after the external shock a speech has been given. Values for speeches given before the external shock will be overwritten in the end as they are negative and will all be set to the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b54a383",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sitzung'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/bt/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sitzung'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f8707ebf9da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# initializes the delay column to be similar to the running session number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"delay\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sitzung\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# the auxiliary column stores an adjustment value which will be added to delay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# for speeches given in legislative period 17, 94 is substracted as the external shock took place inbetween the plenary meetings 94 and 95\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melectoralTerm\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"aux_delay\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m94\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/bt/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/bt/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sitzung'"
     ]
    }
   ],
   "source": [
    "# initializes the delay column to be similar to the running session number\n",
    "df[\"delay\"] = df[\"sitzung\"]\n",
    "# the auxiliary column stores an adjustment value which will be added to delay\n",
    "# for speeches given in legislative period 17, 94 is substracted as the external shock took place inbetween the plenary meetings 94 and 95\n",
    "df.loc[df.electoralTerm <= 17, \"aux_delay\"] = -94\n",
    "# for speeches given in legislative period 18, 159 is added as the external shock took place 159 plenary meetings before the first meeting in legislative period 18\n",
    "df.loc[df.electoralTerm >= 18, \"aux_delay\"] = 253 - 94\n",
    "# the new variable reflects the adjustments from the chunk above\n",
    "df[\"aux_delay_weight\"] = df[\"delay\"] + df[\"aux_delay\"]\n",
    "# sets the variable log_base\n",
    "log_base = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d47e2e",
   "metadata": {},
   "source": [
    "The *log_base* variable is an important argument to the delay weight. Instead of using the delay in number of sessions to punish late speeches / opinion changes, I am choosing to apply a non-linear scale which does not completely invalidate late speeches. Further, it even promotes (attaches more weight to a speech compared to speeches given before the external shock) early speeches just after the external shock up to the point where $aux\\_delay\\_weight = log\\_base$. Thus, choosing $log\\_base = 3$ would\n",
    "\n",
    "As I do not want to punish any speech given before the external shock, the  auxiliary variable *aux_delay_weight* is set to equal the *log_base* value for all speeches before the shock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda0959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.after_shock == 0, \"aux_delay_weight\"] = log_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af66db4",
   "metadata": {},
   "source": [
    "In the next chunk, the non-linear weighting value is completed. As all speeches before the shock have an *aux_delay_weight* equal to *log_base*, the final weight *delay_weight* will be $log_{log\\_base}(log\\_base) = 1$.\n",
    "Accordingly, more importance is attached to speeches in the first two plenary meetings after the external shock. A weight of 1 would be attached to all plenary meetings before the external shock and plenary meeting 3 after the shock. All plenary meetings after number 3 would receive a slowly decreasing importance. For example, meeting 200 after the shock would receive a weight of $\\frac{1}{log_3 200}=\\frac{1}{4.8}$ - the opinions voiced at that time are roughly a fifth as important as an opinion voiced in plenary meeting 3 after the shock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5022b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"delay_weight\"] = df[\"aux_delay_weight\"].apply(lambda x: log(x, log_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce404ca",
   "metadata": {},
   "source": [
    "Lastly, all auxialilary columns no longer needed can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"delay\"]\n",
    "del df[\"aux_delay\"]\n",
    "del df[\"aux_delay_weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf7e43",
   "metadata": {},
   "source": [
    "#### Application of Delay Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe69a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"w_score\"] = df[\"score\"] / df[\"delay_weight\"]\n",
    "df[\"w_score_p\"] = df[\"score_p\"] / df[\"delay_weight\"]\n",
    "df[\"w_score_a\"] = df[\"score_a\"] / df[\"delay_weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ab66e",
   "metadata": {},
   "source": [
    "### Review of Preliminary Results\n",
    "The next chunk returns a sample of rows with strong positive and negative scores. These speech fragments are examples of extremely strong opinions towards nuclear energy politics being voiced in parliament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5635bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\n",
    "    \"display.max_colwidth\",\n",
    "    25,\n",
    "    \"display.precision\",\n",
    "    2,\n",
    "    \"display.float_format\",\n",
    "    lambda x: \"%.2f\" % x,\n",
    "):\n",
    "    print(\n",
    "        df[\n",
    "            [\n",
    "                \"PN_s\",\n",
    "                \"PN_sp\",\n",
    "                \"PN_sa\",\n",
    "                \"AN_s\",\n",
    "                \"AN_sp\",\n",
    "                \"AN_sa\",\n",
    "                \"CE_s\",\n",
    "                \"CE_sp\",\n",
    "                \"CE_sa\",\n",
    "                \"NE_s\",\n",
    "                \"NE_sp\",\n",
    "                \"NE_sa\",\n",
    "                \"score\",\n",
    "                \"score_p\",\n",
    "                \"score_a\",\n",
    "                \"w_score\",\n",
    "                \"w_score_p\",\n",
    "                \"w_score_a\",\n",
    "                \"delay_weight\",\n",
    "            ]\n",
    "        ].describe()\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
