{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb369507",
   "metadata": {},
   "source": [
    "# External Shock on Energy Politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b17a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import spacy\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93616a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gerNLP = spacy.load(\"de_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e9fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/plpr.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7321dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOPIC: ANTI NUCLEAR\n",
    "# Is <keyword> helping to leave nuclear energy (in a sustainable manner)? If yes, the topic fits here.\n",
    "anti_nuclear = [\n",
    "    \"Atomausstieg\",\n",
    "    \"Atomausstieges\",\n",
    "    \"EEG\",\n",
    "    \"EEG-Reform\",\n",
    "    \"EEG-Umlage\",\n",
    "    \"Energieleitungsausbaugesetz\",\n",
    "    \"Energierevolution\",\n",
    "    \"Energiespeicherung\",\n",
    "    \"Energiewende\",\n",
    "    \"Erdgasförderung\",\n",
    "    \"Erneuerbare-Energien-Gesetz\",\n",
    "    \"Erneuerbare-Energien-Gesetzes\",\n",
    "    \"Gaskraftwerk\",\n",
    "    \"Gaskraftwerke\",\n",
    "    \"Gaskraftwerkes\",\n",
    "    \"Gaskraftwerken\",\n",
    "    \"Kernenergiegegner\",\n",
    "    \"Kraft-Wärme-Kopplung\",\n",
    "    \"Kraft-Wärme-Kopplungsgesetz\",\n",
    "    \"KWK\",\n",
    "    \"KWK-Gesetz\",\n",
    "    \"KWKG\",\n",
    "    \"Netzstabilität\",\n",
    "    \"Onshorewindenergie\",\n",
    "    \"Solaranlage\",\n",
    "    \"Solaranlagen\",\n",
    "    \"Solarenergie\",\n",
    "    \"Solarstrom\",\n",
    "    \"Solarstromes\",\n",
    "    \"Solarzelle\",\n",
    "    \"Solarzellen\",\n",
    "    \"Sonnenenergie\",\n",
    "    \"Speichermöglichkeit\",\n",
    "    \"Speichermöglichkeiten\",\n",
    "    \"Speichertechnologie\",\n",
    "    \"Speichertechnologien\",\n",
    "    \"Trassenausbau\",\n",
    "    \"Wasserkraft\",\n",
    "    \"Windenergie\",\n",
    "    \"Ökostrom\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a97cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOPIC: PRO NUCLEAR\n",
    "# Is <keyword> helping to keep nuclear energy? If yes, the topic fits here.\n",
    "pro_nuclear = [\n",
    "    \"AKW\",\n",
    "    \"AKWs\",\n",
    "    \"Atomanlage\",\n",
    "    \"Atomanlagen\",\n",
    "    \"Atomaufsicht\",\n",
    "    \"Atomenergie\",\n",
    "    \"Atomenergiebehörde\",\n",
    "    \"Atomforschung\",\n",
    "    \"Atomgesetz\",\n",
    "    \"Atomgesetzes\",\n",
    "    \"Atomindustrie\",\n",
    "    \"Atomkraftwerk\",\n",
    "    \"Atomkraftwerke\",\n",
    "    \"Atomkraftwerkes\",\n",
    "    \"Atomlobby\",\n",
    "    \"Atommüll\",\n",
    "    \"Atomreaktor\",\n",
    "    \"Atomreaktoren\",\n",
    "    \"Atomreaktores\",\n",
    "    \"Atomsicherheit\",\n",
    "    \"Atomwirtschaft\",\n",
    "    \"Brennelement\",\n",
    "    \"Brennstäbe\",\n",
    "    \"Endlager\",\n",
    "    \"Endlagerung\",\n",
    "    \"Euratom\",\n",
    "    \"Euratom-Vertrag\",\n",
    "    \"Kernenergie\",\n",
    "    \"Kernenergielobby\",\n",
    "    \"Kernenergiewirtschaft\" \"Kernkraft\",\n",
    "    \"Kernkraftwerk\",\n",
    "    \"Kernkraftwerke\",\n",
    "    \"Kernkraftwerkes\",\n",
    "    \"Kernreaktor\",\n",
    "    \"Kernreaktoren\",\n",
    "    \"Kernreaktors\",\n",
    "    \"Laufzeitverlängerung\",\n",
    "    \"Nuklearenergiekommission\",\n",
    "    \"Nuklearmaterial\",\n",
    "    \"Reaktor\",\n",
    "    \"Reaktoren\",\n",
    "    \"Reaktors\",\n",
    "    \"Reaktorsicherheit\",\n",
    "    \"Zwischenlagerung\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0944f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOPIC: CONSERVATIVE ENERGY\n",
    "# Is <keyword> associated with conservative energy and does not fit into the above categories?\n",
    "conservative_energy = [\n",
    "    \"Braunkohlekraftwerk\",\n",
    "    \"Braunkohlekraftwerke\",\n",
    "    \"Braunkohlestrom\",\n",
    "    \"Braunkohleverstromung\",\n",
    "    \"Einspeisevergütung\",\n",
    "    \"Energiepreis\",\n",
    "    \"Energiepreise\",\n",
    "    \"Energiesparen\",\n",
    "    \"Energiesparpotenzial\",\n",
    "    \"Energiestrategie\",\n",
    "    \"Kohle\",\n",
    "    \"Kohlen\",\n",
    "    \"Kohleausstieg\" \"Kohlekraftwerk\",\n",
    "    \"Kohlekraftwerke\",\n",
    "    \"Kohlekraftwerks\",\n",
    "    \"Kohlelobby\",\n",
    "    \"Netzbetreiber\",\n",
    "    \"Primärenergie\",\n",
    "    \"Steinkohlebergbau\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f6aa90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOPIC: NEUTRAL ENERGY\n",
    "# Is <keyword> directly associated with energy politics but does not fit into the above categories?\n",
    "neutral_energy = [\n",
    "    \"Brückentechnologie\",\n",
    "    \"Brückentechnologien\",\n",
    "    \"Emissionshandel\",\n",
    "    \"Energie\",\n",
    "    \"Energieeffizienz\",\n",
    "    \"Energiemix\",\n",
    "    \"Energiemixes\",\n",
    "    \"Energiepolitik\",\n",
    "    \"Energieprogramm\",\n",
    "    \"Energiequelle\",\n",
    "    \"Energiequellen\",\n",
    "    \"Energiesteuer\",\n",
    "    \"Energietechnologie\",\n",
    "    \"Energietechnologien\",\n",
    "    \"Energieunternehmen\",\n",
    "    \"Energieversorgungsunternehmen\",\n",
    "    \"Energiewirtschaft\",\n",
    "    \"Energiewirtschaftsgesetz\",\n",
    "    \"Erdverkabelung\",\n",
    "    \"Kraftwerkbetreiber\",\n",
    "    \"Kraftwerksbetreiber\",\n",
    "    \"Netzentgelt\",\n",
    "    \"Netzentgelte\",\n",
    "    \"Strom\",\n",
    "    \"Stromerzeugung\",\n",
    "    \"Stromproduktion\",\n",
    "    \"Versorgungssicherheit\",\n",
    "    \"Überbrückungstechnologie\",\n",
    "    \"Überbrückungstechnologien\",\n",
    "    \"Übergangszeit\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b23df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stylecloud\n",
    "\n",
    "text = \" \".join(anti_nuclear + pro_nuclear + neutral_energy + conservative_energy)\n",
    "stylecloud.gen_stylecloud(\n",
    "    text=text,\n",
    "    icon_name=\"fas fa-atom\",\n",
    "    palette=\"colorbrewer.qualitative.Dark2_8\",\n",
    "    background_color=\"black\",\n",
    "    gradient=\"horizontal\",\n",
    "    output_name=\"data/atom.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e6b57",
   "metadata": {},
   "source": [
    "![atom wordcloud](data/atom.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b5ac2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizes all topic models in a list of lists\n",
    "topics = [anti_nuclear, pro_nuclear, neutral_energy, conservative_energy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "119fe943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topics_extension(topic):\n",
    "    \"\"\"Extends topic models by lemmatized values of existing content\"\"\"\n",
    "\n",
    "    for i in range(0, len(topic)):\n",
    "        doc = gerNLP(topic[i])  # creates the spaCy document per word\n",
    "        if (\n",
    "            doc != doc[0].lemma_\n",
    "        ):  # states condition: lemma has to differ from existing item value\n",
    "            topic.extend(\n",
    "                [doc[0].lemma_]\n",
    "            )  # adds the lemmatized value to the respective topic model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23466d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell calls the function just defined on all topic models organized through the list of lists \"topics\"\n",
    "for i in range(0, len(topics)):\n",
    "    topics_extension(topics[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3ade9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell organizes all keywords in a common list\n",
    "all_keywords = []\n",
    "all_keywords.extend(anti_nuclear)\n",
    "all_keywords.extend(pro_nuclear)\n",
    "all_keywords.extend(neutral_energy)\n",
    "all_keywords.extend(conservative_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d55eb41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42304, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6b81146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If executable, this filters all speeches and keeps only those which include at least one word from the hardcoded keywords later in the notebook\n",
    "df = df[df[\"text\"].str.contains(\"|\".join(all_keywords))]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9f56a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5646, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd49108",
   "metadata": {},
   "source": [
    "## Algorithm Preparation\n",
    "**Dummy Variable Pre External Shock / After External Shock**<br>\n",
    "The column *after_shock* is a dummy variable to indicate whether a speech fragment is part of a plenary meeting before the catastrophy in Fukushima or thereafter. The inflection point is between the plenary meetings 97 and 98 during the 17th legislative period. Refer to \\ref{pol-dim-ger} \\nameref{pol-dim-ger} for the conclusion how to choose the inflection point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b3353b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"after_shock\"] = np.where((df[\"sitzung\"] <= 97) & (df[\"wahlperiode\"] <= 17), 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb79e28f",
   "metadata": {},
   "source": [
    "## Named Entities Extraction\n",
    "The following chunk prepares the dataframe by adding three columns with empty lists to be populated with information about named entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d46b1e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"NER\"] = \"\"\n",
    "df[\"NER\"] = df[\"NER\"].apply(list)\n",
    "df[\"NER_text\"] = \"\"\n",
    "df[\"NER_text\"] = df[\"NER_text\"].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df9e89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NER(i, doc):\n",
    "    \"\"\"Extracts named entities per speech fragment and stores them in a separate column\"\"\"\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        df.loc[i, \"NER\"].append(ent.text + \";\" + ent.label_)\n",
    "    df.loc[i, \"NER_text\"] = len(df.loc[i, \"NER\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0b05f8",
   "metadata": {},
   "source": [
    "### Opinion Analysis Algorithm\n",
    "#### Dataframe Preparation\n",
    "First things first, additional columns to store the returned information are needed. For each of the three categories, a column to store words and their sentiments are initialized, as well as a numeric column for the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef9dabfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_initialize_fun():\n",
    "    \"\"\"Initializes all columns required for scores & score calculations\"\"\"\n",
    "\n",
    "    # Anti Nuclear Descriptive & Score\n",
    "    df[\"AN_descriptive\"] = \"\"\n",
    "    df[\"AN_descriptive\"] = df[\"AN_descriptive\"].apply(list)\n",
    "    df[\"AN_s\"] = 0\n",
    "    df[\"AN_sp\"] = 0\n",
    "    df[\"AN_s_afer\"] = 0\n",
    "\n",
    "    # Pro Nuclear Descriptive & Score\n",
    "    df[\"PN_descriptive\"] = \"\"\n",
    "    df[\"PN_descriptive\"] = df[\"PN_descriptive\"].apply(list)\n",
    "    df[\"PN_s\"] = 0\n",
    "    df[\"PN_sp\"] = 0\n",
    "    df[\"PN_sa\"] = 0\n",
    "\n",
    "    # Neutral Energy Descriptive & Score\n",
    "    df[\"NE_descriptive\"] = \"\"\n",
    "    df[\"NE_descriptive\"] = df[\"NE_descriptive\"].apply(list)\n",
    "    df[\"NE_s\"] = 0\n",
    "    df[\"NE_sp\"] = 0\n",
    "    df[\"NE_sa\"] = 0\n",
    "\n",
    "    # Conservative Energy Descriptive & Score\n",
    "    df[\"CE_descriptive\"] = \"\"\n",
    "    df[\"CE_descriptive\"] = df[\"CE_descriptive\"].apply(list)\n",
    "    df[\"CE_s\"] = 0\n",
    "    df[\"CE_sp\"] = 0\n",
    "    df[\"CE_sa\"] = 0\n",
    "\n",
    "    # Placeholders for later final score calculation\n",
    "    df[\"score\"] = 0\n",
    "    df[\"score_p\"] = 0\n",
    "    df[\"score_a\"] = 0\n",
    "\n",
    "    # Column to log scoring\n",
    "    df[\"score_log\"] = \"\"\n",
    "    df[\"score_log\"] = df[\"score_log\"].apply(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba73fcd",
   "metadata": {},
   "source": [
    "#### Occasion Counters\n",
    "In order to track occurances of cases, counters of ocassions are initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6668849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_initialize_fun():\n",
    "    \"\"\"Initializes counters to track occurances of steps within the algorithm\"\"\"\n",
    "\n",
    "    global keyword_counter\n",
    "    keyword_counter = 0\n",
    "\n",
    "    global negation_counter\n",
    "    negation_counter = 0\n",
    "\n",
    "    global third_person_counter\n",
    "    third_person_counter = 0\n",
    "\n",
    "    global score_neutral_counter\n",
    "    score_neutral_counter = 0\n",
    "\n",
    "    global score_positive_counter\n",
    "    score_positive_counter = 0\n",
    "\n",
    "    global score_negative_counter\n",
    "    score_negative_counter = 0\n",
    "\n",
    "    global subtree_length_counter\n",
    "    subtree_length_counter = 0\n",
    "\n",
    "    global ancestors_length_counter\n",
    "    ancestors_length_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d212042",
   "metadata": {},
   "source": [
    "#### Sentiment Scoring with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d576f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the package TextBlob for sentiment analysis on German!\n",
    "from textblob_de import TextBlobDE as TextBlob\n",
    "\n",
    "\n",
    "def calc_scores(subtree, negation, third_person):\n",
    "    \"\"\"Takes a list of words and a list of associated negations and returns a total score of the list and a list documenting the score calculation\"\"\"\n",
    "\n",
    "    global score\n",
    "    score = 0\n",
    "    for i in range(0, len(subtree)):\n",
    "        # Extracts the lemma of word i in the list\n",
    "        descriptor = TextBlob(subtree[i].lemma_)\n",
    "        # Looks up the sentiment polarity score in the dictionary\n",
    "        descriptor_sentiment = descriptor.sentiment[0]\n",
    "\n",
    "        # Tracks score taken\n",
    "        if descriptor_sentiment == 0:\n",
    "            global score_neutral_counter\n",
    "            score_neutral_counter += 1\n",
    "        if descriptor_sentiment > 0:\n",
    "            global score_positive_counter\n",
    "            score_positive_counter += 1\n",
    "        if descriptor_sentiment < 0:\n",
    "            global score_negative_counter\n",
    "            score_negative_counter += 1\n",
    "\n",
    "        # Multiplies with the negation sign (either 1 or -1)\n",
    "        descriptor_sentiment_after_negation = descriptor_sentiment * negation[i]\n",
    "        # Multiplies with the third person attribution value (0 or 1)\n",
    "        descriptor_sentiment_after_third_person = (\n",
    "            descriptor_sentiment_after_negation * third_person[i]\n",
    "        )\n",
    "        # Adds the calculated value to the score\n",
    "        score += descriptor_sentiment_after_negation\n",
    "\n",
    "        # Creates the variable 'sentiment_list' for documentation of the procedure of each element of the subtree list\n",
    "        sentiment_list.append(negation[i])\n",
    "        sentiment_list.append(third_person[i])\n",
    "        sentiment_list.append(subtree[i].lemma_)\n",
    "        sentiment_list.append(descriptor_sentiment)\n",
    "\n",
    "    # Returns two lists\n",
    "    return sentiment_list\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc17af",
   "metadata": {},
   "source": [
    "#### Negation Check\n",
    "This function checks for every token associated to a keyword, if it is being negated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fafa9e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negation_fun(list_of_words):\n",
    "    \"\"\"\n",
    "    function takes list of keyword descriptors,\n",
    "    checks if they are negated, returns list of same length\n",
    "    with '1' indicating no negation and '-1' a negation of the keyword descriptor\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(0, len(list_of_words)):\n",
    "        if \"PTKNEG\" in [child.tag_ for child in list_of_words[i].children]:\n",
    "            negation.append(-1)\n",
    "            global negation_counter\n",
    "            negation_counter += 1\n",
    "        else:\n",
    "            negation.append(1)\n",
    "\n",
    "    return negation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d14e906",
   "metadata": {},
   "source": [
    "#### Third-person Check\n",
    "This function checks whether the speaker attributes a sentence with a keyword to another person or organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f4224f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_person_fun(list_of_words):\n",
    "    \"\"\"Checks if the speaker intends to requote another person and returns a binary result\"\"\"\n",
    "\n",
    "    for i in range(0, len(list_of_words)):\n",
    "        is_ent = 0\n",
    "        for token in list_of_words[i].ancestors:\n",
    "            if token.dep_ == \"ROOT\":\n",
    "                children = [child for child in token.children]\n",
    "                for token in children:\n",
    "                    if token.ent_iob == 3:\n",
    "                        is_ent += 1\n",
    "\n",
    "        if is_ent > 0:\n",
    "            third_person.append(0)\n",
    "            global third_person_counter\n",
    "            third_person_counter += 1\n",
    "        else:\n",
    "            third_person.append(1)\n",
    "\n",
    "    return third_person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ffd7c",
   "metadata": {},
   "source": [
    "#### Retrieval of keyword descriptors\n",
    "The retrieval of words describing the keyword is the oxygen to the algorithm. Both quality and quantity impact the explanatory power of the algorithms' output.\n",
    "#### Descendants Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccb442f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree_fun(token):\n",
    "    \"\"\"Takes a token as input and returns descriptive children and the associated negation\"\"\"\n",
    "\n",
    "    global subtree\n",
    "    global negation\n",
    "    negation = []\n",
    "    global third_person\n",
    "    third_person = []\n",
    "\n",
    "    # direct_subtree is a list of the class spacy.tokens.token.Token\n",
    "    subtree = [\n",
    "        descendant\n",
    "        for descendant in token.subtree\n",
    "        if descendant.tag_ not in [\"PTKNEG\"] and descendant.text not in all_keywords\n",
    "    ]\n",
    "    # second level of direct subtree\n",
    "    if subtree != []:\n",
    "        negation_fun(subtree)\n",
    "        third_person_fun(subtree)\n",
    "        global subtree_length_counter\n",
    "        subtree_length_counter += len(subtree)\n",
    "\n",
    "    return subtree\n",
    "    return negation\n",
    "    return third_person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5568c7",
   "metadata": {},
   "source": [
    "#### Ancestors Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3f3a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ancestors_fun(token):\n",
    "    \"\"\"Takes a token as input and returns descriptive children and the associated negation\"\"\"\n",
    "\n",
    "    global ancestors\n",
    "    global negation\n",
    "    negation = []\n",
    "    global third_person\n",
    "    third_person = []\n",
    "\n",
    "    # direct_subtree is a list of the class spacy.tokens.token.Token\n",
    "    ancestors = [\n",
    "        ancestor for ancestor in token.ancestors if ancestor.tag_ not in [\"PTKNEG\"]\n",
    "    ]\n",
    "    # second level of direct subtree\n",
    "    if ancestors != []:\n",
    "        negation_fun(ancestors)\n",
    "        third_person_fun(ancestors)\n",
    "        global ancestors_length_counter\n",
    "        ancestors_length_counter += len(ancestors)\n",
    "\n",
    "    return ancestors\n",
    "    return negation\n",
    "    return third_person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34709c83",
   "metadata": {},
   "source": [
    "#### Descriptors Connected through Auxiliaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fb5599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aux_connected_fun(token):\n",
    "    \"\"\"Bla bla bla\"\"\"\n",
    "\n",
    "    global aux_connected\n",
    "    global negation\n",
    "    negation = []\n",
    "    global third_person\n",
    "    third_person = []\n",
    "\n",
    "    if token.head.pos_ == \"AUX\":\n",
    "        aux_connected = [\n",
    "            child\n",
    "            for child in token.head.children\n",
    "            if child.text not in all_keywords and child.tag_ not in \"PTKNEG\"\n",
    "        ]\n",
    "\n",
    "    if aux_connected != []:\n",
    "        negation_fun(aux_connected)\n",
    "        third_person_fun(aux_connected)\n",
    "        global aux_connected_length_counter\n",
    "        aux_connected_length_counter += len(aux_connected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df3fc68",
   "metadata": {},
   "source": [
    "#### Opinion Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74299725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opinion(i, doc):\n",
    "    \"\"\"Analyses a document for stated opinions\"\"\"\n",
    "\n",
    "    for token in doc:\n",
    "        for j in range(0, len(topics)):\n",
    "            if token.lemma_ in topics[j]:\n",
    "\n",
    "                global keyword_counter\n",
    "                keyword_counter += 1\n",
    "\n",
    "                global sentiment_list\n",
    "                sentiment_list = []\n",
    "\n",
    "                # SUBTREE\n",
    "                # Initializes the intermediate score for this tokens' subtree to 0\n",
    "                token_score_subtree = 0\n",
    "                # Calls the subtree function which returns a list of words and a list of negations\n",
    "                subtree_fun(token)\n",
    "                # On non-empty subtree lists, the score calculation function is called\n",
    "                if subtree != []:\n",
    "                    calc_scores(subtree, negation, third_person)\n",
    "                    token_score_subtree = score\n",
    "\n",
    "                # ANCESTORS\n",
    "                # Initializes intermediate score for this tokens' ancestors description to 0\n",
    "                token_score_ancestors = 0\n",
    "                # Calls the head description functions which returns a list of words and a list of negations\n",
    "                ancestors_fun(token)\n",
    "                # On non-empty head_description lists, the score calculation function is called\n",
    "                if ancestors != []:\n",
    "                    calc_scores(ancestors, negation, third_person)\n",
    "                    token_score_ancestors = score\n",
    "\n",
    "                #               # AUX CONNECTED\n",
    "                #               # Initializes intermediate score for this tokens' auxiliary-connected description to 0\n",
    "                #               token_score_aux_connected = 0\n",
    "                #\n",
    "                #               if token.head.pos_ == 'AUX':\n",
    "                #                   aux_connected_fun(token)\n",
    "                #                   if aux_connected != []:\n",
    "                #                       calc_scores(aux_connected, negation, third_person)\n",
    "                #                       token_score_aux_connected = score\n",
    "\n",
    "                token_score = (\n",
    "                    token_score_subtree + token_score_ancestors\n",
    "                )  # + token_score_aux_connected\n",
    "\n",
    "                if j == 0:\n",
    "                    df.loc[i, \"AN_descriptive\"].append(sentiment_list)\n",
    "                    df.loc[i, \"AN_s\"] += token_score\n",
    "                elif j == 1:\n",
    "                    df.loc[i, \"PN_descriptive\"].append(sentiment_list)\n",
    "                    df.loc[i, \"PN_s\"] += token_score\n",
    "                elif j == 2:\n",
    "                    df.loc[i, \"NE_descriptive\"].append(sentiment_list)\n",
    "                    df.loc[i, \"NE_s\"] += token_score\n",
    "                elif j == 3:\n",
    "                    df.loc[i, \"CE_descriptive\"].append(sentiment_list)\n",
    "                    df.loc[i, \"CE_s\"] += token_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4f7305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def protocol(start_time, end_time):\n",
    "    \"\"\"Creates a protocol with metrics on the execution of the algorithm\"\"\"\n",
    "\n",
    "    duration = end_time - start_time\n",
    "    text = (\n",
    "        \"The algorithm processing duration was \"\n",
    "        + str(round(duration / 60, 1))\n",
    "        + \" minutes.\"\n",
    "    )\n",
    "    text += \"\\n\" + str(keyword_counter) + \" occurances of keywords were identified\"\n",
    "    text += (\n",
    "        \"\\n\"\n",
    "        + str(subtree_length_counter)\n",
    "        + \" words within keywords' subtrees were checked.\"\n",
    "    )\n",
    "    text += (\n",
    "        \"\\n\"\n",
    "        + str(ancestors_length_counter)\n",
    "        + \" words within keywords' ancestors were checked.\"\n",
    "    )\n",
    "    #   text += '\\n'+str(aux_connected_length_counter) +' words connecting keywords and descriptors through auxiliaries were checked.'\n",
    "    text += (\n",
    "        \"\\n\"\n",
    "        + str(third_person_counter)\n",
    "        + \" keywords were used in statements attributed to somebody else by the speaker.\"\n",
    "    )\n",
    "    text += \"\\n\" + str(negation_counter) + \" keywords descriptions were negated.\"\n",
    "    text += (\n",
    "        \"\\n\" + str(score_neutral_counter) + \" descriptions of keywords were neutral.\"\n",
    "    )\n",
    "    text += (\n",
    "        \"\\n\" + str(score_negative_counter) + \" descriptions of keywords were negative.\"\n",
    "    )\n",
    "    text += (\n",
    "        \"\\n\" + str(score_positive_counter) + \" descriptions of keywords were positive.\"\n",
    "    )\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27beacdd",
   "metadata": {},
   "source": [
    "## Algorithm Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d94908ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/seppmacmini/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f864f340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 28s, sys: 1min 16s, total: 8min 45s\n",
      "Wall time: 8min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Initializes columns to store algorithm output\n",
    "column_initialize_fun()\n",
    "\n",
    "# Initializes counters to track occurances of steps within the algorithm\n",
    "counter_initialize_fun()\n",
    "\n",
    "for i, doc in enumerate(gerNLP.pipe(df[\"text\"], batch_size=100)):\n",
    "\n",
    "    get_NER(i, doc)\n",
    "    get_opinion(i, doc)\n",
    "    if i == df.shape[0]:\n",
    "        break\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d003e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The algorithm processing duration was 8.8 minutes.\n",
      "23424 occurances of keywords were identified\n",
      "49122 words within keywords' subtrees were checked.\n",
      "93714 words within keywords' ancestors were checked.\n",
      "8515 keywords were used in statements attributed to somebody else by the speaker.\n",
      "2315 keywords descriptions were negated.\n",
      "138060 descriptions of keywords were neutral.\n",
      "1440 descriptions of keywords were negative.\n",
      "3336 descriptions of keywords were positive.\n"
     ]
    }
   ],
   "source": [
    "protocol(start_time, end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3542e049",
   "metadata": {},
   "source": [
    "### Score Splitting at Inflection Point\n",
    "As it is essential to compare opinions before and after the external shock, both values extracted from the calculated scores in the various categories in conjunction with the dummy variable *after_shock*, which is 0 for pre-shock and 1 for after-shock speech fragments. <br>\n",
    "To do so, pre-shock and after-shock columns for each category are created (i.e. *NE_sp*, *PN_sa*). These are children to the main category score columns (i.e. *NE_s*, *PN_s*). Initially, the children columns take on the same value as the parents. Then, the values are adjusted to 0 if the *after_shock* variable value (0 or 1) does not match with the children score column suffices (pre or after). Accordingly, for all rows with a *after_shock* value of 1, the pre score will be reset to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "743e0b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets all children score columns to equal the parents' values\n",
    "df[\"AN_sp\"] = df[\"AN_s\"]\n",
    "df[\"AN_sa\"] = df[\"AN_s\"]\n",
    "\n",
    "df[\"PN_sp\"] = df[\"PN_s\"]\n",
    "df[\"PN_sa\"] = df[\"PN_s\"]\n",
    "\n",
    "df[\"NE_sp\"] = df[\"NE_s\"]\n",
    "df[\"NE_sa\"] = df[\"NE_s\"]\n",
    "\n",
    "df[\"CE_sp\"] = df[\"CE_s\"]\n",
    "df[\"CE_sa\"] = df[\"CE_s\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "411b8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusts children score columns for their after_shock values\n",
    "df.loc[df.after_shock == 1, [\"AN_sp\", \"PN_sp\", \"NE_sp\", \"CE_sp\"]] = 0\n",
    "df.loc[df.after_shock == 0, [\"AN_sa\", \"PN_sa\", \"NE_sa\", \"CE_sa\"]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65d12e0",
   "metadata": {},
   "source": [
    "### Score Calculation\n",
    "The main score is calculated using three of the four identified models in \\ref{hardcoded-topic-modeling} \\nameref{hardcoded-topic-modeling}. The score is designed to be positive to reflect progressiveness. Therefore, anti-nuclear energy opinions are added, pro-nuclear energy opinions are substracted, and conservative energy politics opinions are substracted as well, as those do not reflect the turnaround performed by politics. Solely opinions about energy politics which do not fall into any of the other three categories are not included in the score but are kept for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "383426b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"] = df[\"AN_s\"] - df[\"PN_s\"] - df[\"CE_s\"]\n",
    "df[\"score_p\"] = df[\"AN_sp\"] - df[\"PN_sp\"] - df[\"CE_sp\"]\n",
    "df[\"score_a\"] = df[\"AN_sa\"] - df[\"PN_sa\"] - df[\"CE_sa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae81b11e",
   "metadata": {},
   "source": [
    "### Delay Weight\n",
    "#### Weight Calculation\n",
    "The delay weight assigns a value between $1$ and $\\log_{log\\_base}(\\infty)$ to each row. Later, the score will be divided by the weight to calculate the tenacity. The later a speech was given after the external shock, the less impact its score has. The delay weight will be useful in the calculation of the measure of tenacity.\n",
    "<br>\n",
    "The column *delay* is supposed to indicate how many sessions after the external shock a speech has been given. Values for speeches given before the external shock will be overwritten in the end as they are negative and will all be set to the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5adc087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializes the delay column to be similar to the running session number\n",
    "df[\"delay\"] = df[\"sitzung\"]\n",
    "# the auxiliary column stores an adjustment value which will be added to delay\n",
    "# for speeches given in legislative period 17, 94 is substracted as the external shock took place inbetween the plenary meetings 94 and 95\n",
    "df.loc[df.wahlperiode == 17, \"aux_delay\"] = -94\n",
    "# for speeches given in legislative period 18, 159 is added as the external shock took place 159 plenary meetings before the first meeting in legislative period 18\n",
    "df.loc[df.wahlperiode == 18, \"aux_delay\"] = 253 - 94\n",
    "# the new variable reflects the adjustments from the chunk above\n",
    "df[\"aux_delay_weight\"] = df[\"delay\"] + df[\"aux_delay\"]\n",
    "# sets the variable log_base\n",
    "log_base = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfdff2b",
   "metadata": {},
   "source": [
    "The *log_base* variable is an important argument to the delay weight. Instead of using the delay in number of sessions to punish late speeches / opinion changes, I am choosing to apply a non-linear scale which does not completely invalidate late speeches. Further, it even promotes (attaches more weight to a speech compared to speeches given before the external shock) early speeches just after the external shock up to the point where $aux\\_delay\\_weight = log\\_base$. Thus, choosing $log\\_base = 3$ would\n",
    "\n",
    "As I do not want to punish any speech given before the external shock, the  auxiliary variable *aux_delay_weight* is set to equal the *log_base* value for all speeches before the shock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c749b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.after_shock == 0, \"aux_delay_weight\"] = log_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da839d85",
   "metadata": {},
   "source": [
    "In the next chunk, the non-linear weighting value is completed. As all speeches before the shock have an *aux_delay_weight* equal to *log_base*, the final weight *delay_weight* will be $log_{log\\_base}(log\\_base) = 1$.\n",
    "Accordingly, more importance is attached to speeches in the first two plenary meetings after the external shock. A weight of 1 would be attached to all plenary meetings before the external shock and plenary meeting 3 after the shock. All plenary meetings after number 3 would receive a slowly decreasing importance. For example, meeting 200 after the shock would receive a weight of $\\frac{1}{log_3 200}=\\frac{1}{4.8}$ - the opinions voiced at that time are roughly a fifth as important as an opinion voiced in plenary meeting 3 after the shock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb7de57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"delay_weight\"] = df[\"aux_delay_weight\"].apply(lambda x: log(x, log_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a65cdd1",
   "metadata": {},
   "source": [
    "Lastly, all auxialilary columns no longer needed can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40471678",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"delay\"]\n",
    "del df[\"aux_delay\"]\n",
    "del df[\"aux_delay_weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16ab203",
   "metadata": {},
   "source": [
    "#### Application of Delay Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4cb6b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"w_score\"] = df[\"score\"] / df[\"delay_weight\"]\n",
    "df[\"w_score_p\"] = df[\"score_p\"] / df[\"delay_weight\"]\n",
    "df[\"w_score_a\"] = df[\"score_a\"] / df[\"delay_weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c15ed",
   "metadata": {},
   "source": [
    "### Review of Preliminary Results\n",
    "The next chunk returns a sample of rows with strong positive and negative scores. These speech fragments are examples of extremely strong opinions towards nuclear energy politics being voiced in parliament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a887a21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PN_s   PN_sp   PN_sa    AN_s   AN_sp   AN_sa    CE_s   CE_sp   CE_sa  \\\n",
      "count 5646.00 5646.00 5646.00 5646.00 5646.00 5646.00 5646.00 5646.00 5646.00   \n",
      "mean     0.02    0.01    0.01    0.07    0.01    0.06    0.01    0.00    0.00   \n",
      "std      0.38    0.29    0.25    0.51    0.18    0.48    0.17    0.11    0.13   \n",
      "min     -4.00   -4.00   -3.50   -4.30   -4.00   -4.30   -2.00   -2.00   -2.00   \n",
      "25%      0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
      "50%      0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
      "75%      0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
      "max      7.30    4.50    7.30    9.20    5.80    9.20    2.70    2.70    2.00   \n",
      "\n",
      "         NE_s   NE_sp   NE_sa   score  score_p  score_a  w_score  w_score_p  \\\n",
      "count 5646.00 5646.00 5646.00 5646.00  5646.00  5646.00  5646.00    5646.00   \n",
      "mean     0.15    0.05    0.09    0.04    -0.01     0.05     0.00      -0.01   \n",
      "std      0.68    0.42    0.55    0.65     0.35     0.55     0.38       0.35   \n",
      "min     -3.00   -3.00   -3.00   -6.60    -5.20    -6.60    -5.20      -5.20   \n",
      "25%      0.00    0.00    0.00    0.00     0.00     0.00     0.00       0.00   \n",
      "50%      0.00    0.00    0.00    0.00     0.00     0.00     0.00       0.00   \n",
      "75%      0.00    0.00    0.00    0.00     0.00     0.00     0.00       0.00   \n",
      "max     11.70   11.70    6.00    9.20     5.80     9.20     5.80       5.80   \n",
      "\n",
      "       w_score_a  delay_weight  \n",
      "count    5646.00       5646.00  \n",
      "mean        0.01          3.19  \n",
      "std         0.14          1.56  \n",
      "min        -1.48          1.00  \n",
      "25%         0.00          1.00  \n",
      "50%         0.00          3.89  \n",
      "75%         0.00          4.53  \n",
      "max         2.26          5.09  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context(\n",
    "    \"display.max_colwidth\",\n",
    "    25,\n",
    "    \"display.precision\",\n",
    "    2,\n",
    "    \"display.float_format\",\n",
    "    lambda x: \"%.2f\" % x,\n",
    "):\n",
    "    print(\n",
    "        df[\n",
    "            [\n",
    "                \"PN_s\",\n",
    "                \"PN_sp\",\n",
    "                \"PN_sa\",\n",
    "                \"AN_s\",\n",
    "                \"AN_sp\",\n",
    "                \"AN_sa\",\n",
    "                \"CE_s\",\n",
    "                \"CE_sp\",\n",
    "                \"CE_sa\",\n",
    "                \"NE_s\",\n",
    "                \"NE_sp\",\n",
    "                \"NE_sa\",\n",
    "                \"score\",\n",
    "                \"score_p\",\n",
    "                \"score_a\",\n",
    "                \"w_score\",\n",
    "                \"w_score_p\",\n",
    "                \"w_score_a\",\n",
    "                \"delay_weight\",\n",
    "            ]\n",
    "        ].describe()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba20a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
